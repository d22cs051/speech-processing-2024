{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6666666666666665, array(0.56666667))\n"
     ]
    }
   ],
   "source": [
    "# source: https://stackoverflow.com/questions/28339746/equal-error-rate-in-python\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y = [1, 1, 0, 0, 1]\n",
    "y_score = [0.3, 0.1, 0.4, 0.8, 0.9]\n",
    "def cal_eer(y, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh\n",
    "\n",
    "print(cal_eer(y, y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Uncomment to convert m4a to wav with respect to the directory structure\n",
    "\n",
    "# # converting m4a to wav and saving to new directory\n",
    "# from pydub import AudioSegment\n",
    "# from pathlib import Path\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# audio_path = Path(\"../../data/kb_data_clean_m4a/hindi/valid/audio\")\n",
    "# wav_path = Path(\"../../data/kb_data_clean_m4a/hindi/valid/wav\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # print(list(audio_path.glob(\"*.m4a\"))[:5])\n",
    "# all_m4a_files = list(audio_path.glob(\"*.m4a\"))\n",
    "# for audio_file in tqdm(all_m4a_files):\n",
    "#     audio = AudioSegment.from_file(str(audio_file))\n",
    "#     audio.export(\"../../data/kb_data_clean_m4a/hindi/valid/wav/\"+str(audio_file).split(\"/\")[-1].replace('m4a','wav'), format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>person1</th>\n",
       "      <th>person2</th>\n",
       "      <th>ecapa_tdnn</th>\n",
       "      <th>hubert_large</th>\n",
       "      <th>wavlm_base_plus</th>\n",
       "      <th>wavlm_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>id10001/Y8hIVOBuels/00001.wav</td>\n",
       "      <td>id10001/utrA-v8pPm4/00001.wav</td>\n",
       "      <td>0.958375</td>\n",
       "      <td>0.990806</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.991306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>id10001/Y8hIVOBuels/00001.wav</td>\n",
       "      <td>id10341/rX4LkvzySSM/00014.wav</td>\n",
       "      <td>0.986570</td>\n",
       "      <td>0.992295</td>\n",
       "      <td>0.987697</td>\n",
       "      <td>0.991324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>id10001/Y8hIVOBuels/00001.wav</td>\n",
       "      <td>id10001/zELwAz2W6hM/00010.wav</td>\n",
       "      <td>0.983272</td>\n",
       "      <td>0.991810</td>\n",
       "      <td>0.986436</td>\n",
       "      <td>0.989566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>id10001/Y8hIVOBuels/00001.wav</td>\n",
       "      <td>id10341/5DAommAsxmE/00007.wav</td>\n",
       "      <td>0.990401</td>\n",
       "      <td>0.990836</td>\n",
       "      <td>0.985041</td>\n",
       "      <td>0.989352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>id10001/Y8hIVOBuels/00002.wav</td>\n",
       "      <td>id10001/zELwAz2W6hM/00005.wav</td>\n",
       "      <td>0.988819</td>\n",
       "      <td>0.993271</td>\n",
       "      <td>0.989406</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                        person1                        person2  \\\n",
       "0      1  id10001/Y8hIVOBuels/00001.wav  id10001/utrA-v8pPm4/00001.wav   \n",
       "1      0  id10001/Y8hIVOBuels/00001.wav  id10341/rX4LkvzySSM/00014.wav   \n",
       "2      1  id10001/Y8hIVOBuels/00001.wav  id10001/zELwAz2W6hM/00010.wav   \n",
       "3      0  id10001/Y8hIVOBuels/00001.wav  id10341/5DAommAsxmE/00007.wav   \n",
       "4      1  id10001/Y8hIVOBuels/00002.wav  id10001/zELwAz2W6hM/00005.wav   \n",
       "\n",
       "   ecapa_tdnn  hubert_large  wavlm_base_plus  wavlm_large  \n",
       "0    0.958375      0.990806         0.986654     0.991306  \n",
       "1    0.986570      0.992295         0.987697     0.991324  \n",
       "2    0.983272      0.991810         0.986436     0.989566  \n",
       "3    0.990401      0.990836         0.985041     0.989352  \n",
       "4    0.988819      0.993271         0.989406     0.992200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataframes \n",
    "import pandas as pd\n",
    "df_voxceleb = pd.read_csv(\"/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/downstreams/speaker_verification/verification_scores_vox_batch_128.csv\")\n",
    "df_voxceleb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ecapa_tdnn, EER: 0.41272242894583616\n",
      "Model: hubert_large, EER: 0.4788619852968679\n",
      "Model: wavlm_base_plus, EER: 0.4765510117467778\n",
      "Model: wavlm_large, EER: 0.4735674803044982\n"
     ]
    }
   ],
   "source": [
    "# calculating EER model wise\n",
    "labels = df_voxceleb['label']\n",
    "scores_model_dict = {\n",
    "    \"ecapa_tdnn\": df_voxceleb['ecapa_tdnn'],\n",
    "    \"hubert_large\": df_voxceleb['hubert_large'],\n",
    "    \"wavlm_base_plus\": df_voxceleb['wavlm_base_plus'],\n",
    "    \"wavlm_large\": df_voxceleb['wavlm_large'],\n",
    "}\n",
    "\n",
    "for model, scores in scores_model_dict.items():\n",
    "    # converting scores (-1,1) -> (0,1)\n",
    "    scores = (scores + 1) / 2\n",
    "    eer, thresh = cal_eer(labels, scores)\n",
    "    print(f\"Model: {model}, EER: {eer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>person1</th>\n",
       "      <th>person2</th>\n",
       "      <th>ecapa_tdnn</th>\n",
       "      <th>hubert_large</th>\n",
       "      <th>wavlm_base_plus</th>\n",
       "      <th>wavlm_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>0.982102</td>\n",
       "      <td>0.975679</td>\n",
       "      <td>0.979226</td>\n",
       "      <td>0.982783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>0.993843</td>\n",
       "      <td>0.986117</td>\n",
       "      <td>0.984444</td>\n",
       "      <td>0.984283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>0.989320</td>\n",
       "      <td>0.988016</td>\n",
       "      <td>0.986069</td>\n",
       "      <td>0.983059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>0.979724</td>\n",
       "      <td>0.984716</td>\n",
       "      <td>0.986421</td>\n",
       "      <td>0.985397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...</td>\n",
       "      <td>0.901027</td>\n",
       "      <td>0.972380</td>\n",
       "      <td>0.978996</td>\n",
       "      <td>0.971999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            person1  \\\n",
       "0      0  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...   \n",
       "1      1  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...   \n",
       "2      1  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...   \n",
       "3      0  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...   \n",
       "4      1  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...   \n",
       "\n",
       "                                             person2  ecapa_tdnn  \\\n",
       "0  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...    0.982102   \n",
       "1  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...    0.993843   \n",
       "2  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...    0.989320   \n",
       "3  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...    0.979724   \n",
       "4  /DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb...    0.901027   \n",
       "\n",
       "   hubert_large  wavlm_base_plus  wavlm_large  \n",
       "0      0.975679         0.979226     0.982783  \n",
       "1      0.986117         0.984444     0.984283  \n",
       "2      0.988016         0.986069     0.983059  \n",
       "3      0.984716         0.986421     0.985397  \n",
       "4      0.972380         0.978996     0.971999  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataframes \n",
    "import pandas as pd\n",
    "df_hindi = pd.read_csv(\"/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/downstreams/speaker_verification/verification_scores_hindi_batch_128.csv\")\n",
    "df_hindi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ecapa_tdnn, EER: 0.363457681508223\n",
      "Model: hubert_large, EER: 0.38815317112192127\n",
      "Model: wavlm_base_plus, EER: 0.42317510969336003\n",
      "Model: wavlm_large, EER: 0.41407942238246065\n"
     ]
    }
   ],
   "source": [
    "# calculating EER model wise\n",
    "labels = df_hindi['label']\n",
    "scores_model_dict = {\n",
    "    \"ecapa_tdnn\": df_hindi['ecapa_tdnn'],\n",
    "    \"hubert_large\": df_hindi['hubert_large'],\n",
    "    \"wavlm_base_plus\": df_hindi['wavlm_base_plus'],\n",
    "    \"wavlm_large\": df_hindi['wavlm_large'],\n",
    "}\n",
    "\n",
    "for model, scores in scores_model_dict.items():\n",
    "    # converting scores (-1,1) -> (0,1)\n",
    "    scores = (scores + 1) / 2\n",
    "    eer, thresh = cal_eer(labels, scores)\n",
    "    print(f\"Model: {model}, EER: {eer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchaudio.sox_effects import apply_effects_file\n",
    "import os\n",
    "\n",
    "EFFECTS = [\n",
    "# [\"channels\", \"1\"],\n",
    "# [\"rate\", \"16000\"],\n",
    "[\"gain\", \"-3.0\"],\n",
    "[\"silence\", \"1\", \"0.1\", \"0.1%\", \"-1\", \"0.1\", \"0.1%\"],\n",
    "]\n",
    "\n",
    "class SpeakerVerifi_test(Dataset):\n",
    "    def __init__(self, vad_config, file_path, meta_data):\n",
    "        self.root = file_path\n",
    "        self.meta_data = meta_data\n",
    "        self.necessary_dict = self.processing()\n",
    "        self.vad_c = vad_config \n",
    "        self.dataset = self.necessary_dict['pair_table'] \n",
    "        \n",
    "    def processing(self):\n",
    "        pair_table = []\n",
    "        with open(self.meta_data, \"r\") as f:\n",
    "            usage_list = f.readlines()\n",
    "        for pair in usage_list:\n",
    "            list_pair = pair.split()\n",
    "            pair_1= os.path.join(self.root, list_pair[1].split(\"/\")[-1])\n",
    "            pair_2= os.path.join(self.root, list_pair[2].split(\"/\")[-1])\n",
    "            one_pair = [list_pair[0],pair_1,pair_2 ]\n",
    "            pair_table.append(one_pair)\n",
    "        # print(f\"printing pair_table: {pair_table[:2]}\") # NOTE: testing purpose only\n",
    "        return {\n",
    "            \"spk_paths\": None,\n",
    "            \"total_spk_num\": None,\n",
    "            \"pair_table\": pair_table\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.necessary_dict['pair_table'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y_label, x1_path, x2_path = self.dataset[idx]\n",
    "        def path2name(path):\n",
    "            return path#Path(\"-\".join((Path(path).parts)[-3:])).stem\n",
    "\n",
    "        x1_name = path2name(x1_path)\n",
    "        x2_name = path2name(x2_path)\n",
    "\n",
    "        wav1, _ = apply_effects_file(x1_path, EFFECTS)\n",
    "        wav2, _ = apply_effects_file(x2_path, EFFECTS)\n",
    "\n",
    "        wav1 = wav1.squeeze(0)\n",
    "        wav2 = wav2.squeeze(0)\n",
    "\n",
    "        \n",
    "        return wav1.numpy(), wav2.numpy(), x1_name, x2_name, int(y_label[0])\n",
    "\n",
    "    def collate_fn(self, data_sample):\n",
    "        wavs1, wavs2, x1_names, x2_names, ylabels = zip(*data_sample)\n",
    "        all_wavs = wavs1 + wavs2\n",
    "        all_names = x1_names + x2_names\n",
    "        return all_wavs, all_names, ylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_dataset = SpeakerVerifi_test(file_path=\"/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb_data_clean_m4a/hindi/valid/wav\", meta_data=\"/DATA1/bikash_dutta/CS/SP/A2/UniSpeech/data/kb_data_clean_m4a/meta_data/hindi/valid_data.txt\", vad_config=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
